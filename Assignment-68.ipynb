{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30640c7b-e575-4268-bc06-08adae1cf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997c56fa-0f4f-44de-9bbd-790a8d1f2f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Titanic_train.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3900bf-a068-4f98-9db7-67c72afd7af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "#1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "\n",
    "#Design a pipeline that includes the following steps:\n",
    "\n",
    "#Use an automated feature selection method to identify the important features in the dataset.\n",
    "#Create a numerical pipeline that includes the following steps:\n",
    "#Impute the missing values in the numerical columns using the mean of the column values.\n",
    "#Scale the numerical columns using standardisation.\n",
    "#Create a categorical pipeline that includes the following steps:\n",
    "#Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "#One-hot encode the categorical columns.\n",
    "#Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "#Use a Random Forest Classifier to build the final model.\n",
    "#Evaluate the accuracy of the model on the test dataset.\n",
    "\n",
    "#Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline.\n",
    "\n",
    "#Ans\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv(\"Titanic_train.csv\")\n",
    "\n",
    "# Step 2: Define the features and target variable\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Define the column transformer for preprocessing\n",
    "numeric_features = ['Age', 'Fare']\n",
    "categorical_features = ['Sex', 'Pclass', 'Embarked']\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Use automated feature selection\n",
    "feature_selection = SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "# Step 6: Create the final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Step 7: Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28eaf79-a82d-45be-ba68-0b8f09fc7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266988eb-7f1a-4738-bfed-3e712c4ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1            5.1           3.5            1.4           0.2   \n",
      "1      2            4.9           3.0            1.4           0.2   \n",
      "2      3            4.7           3.2            1.3           0.2   \n",
      "3      4            4.6           3.1            1.5           0.2   \n",
      "4      5            5.0           3.6            1.4           0.2   \n",
      "..   ...            ...           ...            ...           ...   \n",
      "145  146            6.7           3.0            5.2           2.3   \n",
      "146  147            6.3           2.5            5.0           1.9   \n",
      "147  148            6.5           3.0            5.2           2.0   \n",
      "148  149            6.2           3.4            5.4           2.3   \n",
      "149  150            5.9           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Iris.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e9d546-ff70-4360-a778-e8e494c6caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy.\n",
    "\n",
    "#Ans\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Step 2: Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop(\"Species\", axis=1)\n",
    "y = data[\"Species\"]\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create the individual classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Step 5: Create the voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_classifier),\n",
    "    ('lr', lr_classifier)\n",
    "])\n",
    "\n",
    "# Step 6: Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('voting_classifier', voting_classifier)\n",
    "])\n",
    "\n",
    "# Step 7: Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the accuracy of the pipeline\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fc630-fba1-4b50-8dfb-8c49351c311b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
